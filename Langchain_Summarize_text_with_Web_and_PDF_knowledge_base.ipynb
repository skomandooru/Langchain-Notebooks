{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Let's summarize text from multiple documents using Langchains, LangGraph, Claude Sonnet 3.5 LLM from the Langchain Documentation\n",
        "\n",
        "[Langchain Documentation for Summarization](https://python.langchain.com/docs/tutorials/summarization/)"
      ],
      "metadata": {
        "id": "w5ea-ACh8BVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concepts:\n",
        "\n",
        "*  Using language models.\n",
        "*  Using document loaders, specifically the WebBaseLoader to load content from an HTML webpage.\n",
        "\n",
        "\n",
        "Two ways to summarize or combine multiple documents:\n",
        "1. Stuff, which simply concatenates documents into a prompt\n",
        "2. Map-reduce, for larger sets of documents. This splits documents into batches, summarizes those, and then summarizes the summaries."
      ],
      "metadata": {
        "id": "uwwnstvd8_8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Case for Stuff: You have a set of documents (PDFs, Blogs, customer questions, etc.) and you want to summarize the content.\n",
        "\n",
        "Use Case for MapReduce: A professor has a research paper from Google Scholar that is 30 pages long, he has 10 minutes to summarize the content of the paper."
      ],
      "metadata": {
        "id": "CFjk5j0VQrT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's install the necessary libraries"
      ],
      "metadata": {
        "id": "II9-24AeADmI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kc_bsvi37eOd"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet tiktoken langchain langgraph beautifulsoup4 langchain-community langchain-aws"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put in your API Key Credentials and Ensure it works"
      ],
      "metadata": {
        "id": "ejqZprw3ASmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will be loading in our documents. We will use WebBaseLoader to load a blog post:"
      ],
      "metadata": {
        "id": "4ayeCUwgAatn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZECPlH_rAlIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select your AWS chat model and Ensure that your credentials are configured"
      ],
      "metadata": {
        "id": "pVnYBwWzAuAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure your AWS credentials are configured\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"anthropic.claude-3-5-sonnet-20240620-v1:0\", model_provider=\"bedrock_converse\")"
      ],
      "metadata": {
        "id": "F-piflf_Bdfj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1: Stuff: summarize in a single LLM call\n",
        "\n",
        "The chain will take a list of documents, insert them all into a prompt, and pass that prompt to an LLM:"
      ],
      "metadata": {
        "id": "9Pq8XgFCBfn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Define prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", \"You are a smart and helpful AI assistant that summarizes documents!\"),\n",
        "     (\"user\", \"Summarize the following blog:\\n\\n{context}\")]\n",
        ")\n",
        "\n",
        "# Instantiate chain\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Invoke chain\n",
        "result = chain.invoke({\"context\": docs})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkvbpp7qC_ED",
        "outputId": "62c4e0b9-0879-4525-b3a4-9e1b3edee9d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a summary of the key points from the blog post on LLM-powered autonomous agents:\n",
            "\n",
            "1. Overview of agent system components:\n",
            "- Planning (task decomposition, self-reflection)\n",
            "- Memory (short-term, long-term)\n",
            "- Tool use (external APIs and capabilities)\n",
            "\n",
            "2. Planning techniques:\n",
            "- Chain of thought reasoning\n",
            "- Tree of Thoughts for exploring multiple reasoning paths\n",
            "- Self-reflection to improve from past actions\n",
            "\n",
            "3. Memory types:\n",
            "- Short-term: In-context learning within limited context window\n",
            "- Long-term: External vector stores with fast retrieval\n",
            "\n",
            "4. Tool use approaches:  \n",
            "- MRKL system for routing to expert modules\n",
            "- Fine-tuning LMs to use external APIs (TALM, Toolformer)\n",
            "- ChatGPT plugins and function calling\n",
            "\n",
            "5. Case studies:\n",
            "- Scientific discovery agents (ChemCrow)\n",
            "- Generative agent simulations (25 AI characters interacting)\n",
            "\n",
            "6. Proof-of-concept demos:\n",
            "- AutoGPT \n",
            "- GPT-Engineer\n",
            "\n",
            "7. Key challenges:\n",
            "- Limited context length\n",
            "- Difficulties with long-term planning\n",
            "- Reliability issues with natural language interfaces\n",
            "\n",
            "The post provides an overview of the key components and techniques for building autonomous agents powered by large language models, as well as highlighting some of the current limitations and challenges in this area.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, that we summarized text from a blog, let's summarize a pdf using a pdf based loader!"
      ],
      "metadata": {
        "id": "vmd_OzlpEhij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7JI0XJWMUxi",
        "outputId": "bba94e2d-c198-457c-caa4-28770db89271"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.5.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Downloading pypdf-5.5.0-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load and chunk contents of the PDF\n",
        "\n",
        "file_path = \"/content/summarize/edfors-et-al-gene.pdf\"  # Replace with your PDF path\n",
        "loader = PyPDFLoader(file_path)\n",
        "\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "ucOdx_tYKd9Z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Define prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", \"You are a smart and helpful AI assistant that summarizes documents!\"),\n",
        "     (\"user\", \"Summarize the following pdf:\\n\\n{context}\")]\n",
        ")\n",
        "\n",
        "# Instantiate chain\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Invoke chain\n",
        "result = chain.invoke({\"context\": docs})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxfMICPuMZA1",
        "outputId": "31b5ecba-e6fd-460e-bc53-fc20587dfea2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a summary of the key points from the article:\n",
            "\n",
            "- The study investigated the correlation between mRNA levels and protein levels for a set of 55 genes across 9 human cell lines and 11 human tissues.\n",
            "\n",
            "- They used targeted proteomics with internal standards to measure absolute protein copy numbers, and compared these to mRNA levels measured by RNA-seq.\n",
            "\n",
            "- They found that mRNA and protein levels did not correlate well when compared directly. However, introducing a gene-specific RNA-to-protein (RTP) conversion factor significantly improved the correlation.\n",
            "\n",
            "- The RTP conversion factor was found to be relatively consistent for a given gene across different cell types and tissues, but varied widely between different genes (from hundreds to hundreds of thousands of protein copies per mRNA).\n",
            "\n",
            "- Using the gene-specific RTP factors allowed protein copy numbers to be predicted from mRNA levels with good accuracy across different samples.\n",
            "\n",
            "- They developed a histone-based method to normalize for cell numbers in tissue samples.\n",
            "\n",
            "- The results suggest transcriptomics data can be used to predict protein levels if gene-specific conversion factors are applied, providing a link between genomics and proteomics data.\n",
            "\n",
            "- The authors propose determining RTP factors for all protein-coding genes to enable proteome-wide predictions from transcriptomics data.\n",
            "\n",
            "In summary, the study demonstrates that mRNA levels can predict protein levels if gene-specific conversion factors are used, enhancing the utility of transcriptomics data for estimating protein abundances. This provides an important connection between genomics and proteomics approaches.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, I did not use MapReduce, but it's commonly used for summarizing lots of pages of text in a short amount of time. I mentioned the use case for MapReduce above."
      ],
      "metadata": {
        "id": "nSyuCPlhOPYn"
      }
    }
  ]
}