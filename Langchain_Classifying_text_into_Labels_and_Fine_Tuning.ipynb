{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Used Langchain, Claude Sonnet 3.5 LLM, AWS to classify text into categories or labels using chat models with structured outputs.\n",
        "\n",
        "[Langchain Documentation](https://python.langchain.com/docs/tutorials/classification/)"
      ],
      "metadata": {
        "id": "CCwJHYicePC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tagging means labeling a document with classes such as:\n",
        "\n",
        "*   Sentiment\n",
        "*   Language\n",
        "*   Style (formal, informal etc.)\n",
        "*   Covered topics\n",
        "*   Political tendency"
      ],
      "metadata": {
        "id": "h9B1NKQ7ilFM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installed all the necessary libraries for to run with Langchain"
      ],
      "metadata": {
        "id": "L3ZoYUxSp9FY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet langchain-core langchain-aws"
      ],
      "metadata": {
        "id": "uyiSAgpHfWkO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put in your API Keys for AWS and Ensure that they work"
      ],
      "metadata": {
        "id": "rxKR5yoZgMOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select a chat model from AWS and Load it"
      ],
      "metadata": {
        "id": "c0fsy7lyge1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure your AWS credentials are configured\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"anthropic.claude-3-5-sonnet-20240620-v1:0\", model_provider=\"bedrock_converse\")"
      ],
      "metadata": {
        "id": "zQKwTtIcgW-e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's specify a Pydantic model with a few properties and their expected type in our schema."
      ],
      "metadata": {
        "id": "F5XE3xfRgmfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "# from langchain_openai import ChatOpenAI -> Didn't use OpenAI Keys, so commented this line out\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "tagging_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "Extract the desired information from the following passage.\n",
        "\n",
        "Only extract the properties mentioned in the 'Classification' function.\n",
        "\n",
        "Passage:\n",
        "{input}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "class Classification(BaseModel):\n",
        "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
        "    aggressiveness: int = Field(\n",
        "        description=\"How aggressive the text is on a scale from 1 to 10\"\n",
        "    )\n",
        "    language: str = Field(description=\"The language the text is written in\")\n",
        "\n",
        "\n",
        "# Structured LLM\n",
        "structured_llm = llm.with_structured_output(Classification)"
      ],
      "metadata": {
        "id": "_V9f4tDBgwRN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's call the LLM for the response"
      ],
      "metadata": {
        "id": "oCiRB3Zul-Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "response = structured_llm.invoke(prompt)\n",
        "\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYtE7Cu1lo4W",
        "outputId": "a04bf2c8-855c-422d-8940-547132da4f09"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classification(sentiment='Positive', aggressiveness=1, language='Spanish')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want dictionary output, we can just call .model_dump()"
      ],
      "metadata": {
        "id": "I4HVQPTLmNrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "response = structured_llm.invoke(prompt)\n",
        "\n",
        "response.model_dump()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWl7-tNlmUZo",
        "outputId": "8ac84689-54e4-4f21-bc13-80f06f199692"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentiment': 'Negative', 'aggressiveness': 9, 'language': 'Spanish'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see in the examples, it correctly interprets what we want.\n",
        "\n",
        "The results vary so that we may get, for example, sentiments in different languages ('positive', 'enojado' etc.).\n",
        "\n",
        "We will see how to control these results in the next section."
      ],
      "metadata": {
        "id": "SkRRXJZ-md_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine Tuning the Classification Model"
      ],
      "metadata": {
        "id": "aByaPif6qyM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Careful schema definition gives us more control over the model's output.\n",
        "\n",
        "Specifically, we can define:\n",
        "\n",
        "*   Possible values for each property\n",
        "*   Description to make sure that the model understands the property\n",
        "*   Required properties to be returned\n",
        "\n",
        "Let's redeclare our Pydantic model to control for each of the previously mentioned aspects using enums:"
      ],
      "metadata": {
        "id": "GKp2Qn1xq_xU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classification(BaseModel):\n",
        "    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n",
        "    aggressiveness: int = Field(\n",
        "        ...,\n",
        "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
        "        enum=[1, 2, 3, 4, 5],\n",
        "    )\n",
        "    language: str = Field(\n",
        "        ..., enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"]\n",
        "    )"
      ],
      "metadata": {
        "id": "Cyjc71bmqvPX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain langchain-aws pydantic"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fQAB9S28vI9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is the alternative for what the documentation has for using the OpenAI model."
      ],
      "metadata": {
        "id": "jOJWm98svkhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_aws import ChatBedrockConverse\n",
        "\n",
        "# Step 1: Initialize Claude via Bedrock Converse\n",
        "llm = ChatBedrockConverse(\n",
        "    model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",  # or another supported model\n",
        "    temperature=0\n",
        ").with_structured_output(Classification)"
      ],
      "metadata": {
        "id": "SnMYZj7tvNpm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "llm.invoke(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFYkW_gFvUSP",
        "outputId": "403504ff-ece9-439d-847d-ca8da374c958"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classification(sentiment='happy', aggressiveness=1, language='spanish')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second Input is another spanish sentence, the model will classify the sentiment for this sentence."
      ],
      "metadata": {
        "id": "Lgvcr_Wiv7bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "llm.invoke(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbN00PR9wLd9",
        "outputId": "4eb348fb-75c4-4108-ae43-5ed8e5016e5b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classification(sentiment='sad', aggressiveness=5, language='spanish')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Input, let's see what the model tells us!"
      ],
      "metadata": {
        "id": "CHMqcX9-rZcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"Weather is ok here, I can go outside without much more than a coat\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "llm.invoke(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMtz13d7wbi5",
        "outputId": "2ec4349f-be4e-4f83-c1eb-68abbf869f6a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classification(sentiment='neutral', aggressiveness=1, language='english')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}